---
title: "Research Topics"
permalink: /ResearchTopics/
author_profile: true
---

**[Medical Data Mining](#fau)** &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; **[Time Series Forecasting](#rau)** &nbsp; &nbsp; **[Computer Vision](#cau)**  
**[Natural Language Processing](#cau)** &nbsp; &nbsp; **[Learning Analytics](#cau)** &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; **[AI for Drug Design](#cau)**  
**[Explainable AI (XAI)](#cau)** &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; **[Optimization](#cau)**  


<h2 id="fau">
Medical Data Mining
</h2>

[**[JF006](https://chengtang-ai.github.io/JournalPublications/)**]. **A novel multivariate time series forecasting dendritic neuron model for COVID-19 pandemic transmission tendency.**  
![image](https://github.com/user-attachments/assets/5296a915-f22f-49bb-8301-f6eb3bb521fd)  
A novel coronavirus discovered in late 2019 (COVID-19) quickly spread into a global epidemic and, thankfully, was brought under control by 2022. Because of the virus’s unknown mutations and the vaccine’s waning potency, forecasting is still essential for resurgence prevention and medical resource management. Computational efficiency and long-term accuracy are two bottlenecks for national-level forecasting. This study develops a novel multivariate time series forecasting model, the densely connected highly flexible dendritic neuron model (DFDNM) to predict daily and weekly positive COVID-19 cases. DFDNM’s high flexibility mechanism improves its capacity to deal with nonlinear challenges. The dense introduction of shortcut connections alleviates the vanishing and exploding gradient problems, encourages feature reuse, and improves feature extraction. To deal with the rapidly growing parameters, an improved variation of the adaptive moment estimation (AdamW) algorithm is employed as the learning algorithm for the DFDNM because of its strong optimization ability. The experimental results and statistical analysis conducted across three Japanese prefectures confirm the efficacy and feasibility of the DFDNM while outperforming various state-of-the-art machine learning models. To the best of our knowledge, the proposed DFDNM is the first to restructure the dendritic neuron model’s neural architecture, demonstrating promising use in multivariate time series prediction. Because of its optimal performance, the DFDNM may serve as an important reference for national and regional government decision-makers aiming to optimize pandemic prevention and medical resource management. We also verify that DFDMN is efficiently applicable not only to COVID-19 transmission prediction, but also to more general multivariate prediction tasks. It leads us to believe that it might be applied as a promising prediction model in other fields.  

[**[JF001](https://chengtang-ai.github.io/JournalPublications/)**]. **A novel machine learning technique for computer-aided diagnosis.**  
![image](https://github.com/user-attachments/assets/4cc40ec5-8e43-46ae-8012-fdda7add30aa)  
The primary motivation of this paper is twofold: first, to employ a heuristic optimization algorithm to optimize the dendritic neuron model (DNM) and second, to design a tidy visual classifier for computer-aided diagnosis that can be easily implemented on a hardware system. Considering that the backpropagation (BP) algorithm is sensitive to the initial conditions and can easily fall into local minima, we propose an evolutionary dendritic neuron model (EDNM), which is optimized by the gbest-guided artificial bee colony (GABC) algorithm. The experiments are performed on the Liver Disorders Data Set, the Wisconsin Breast Cancer Data Set, the Haberman’s Survival Data Set, the Diabetic Retinopathy Debrecen Data Set and Hepatitis Data Set, and the effectiveness of our model was rigorously validated in terms of the classification accuracy, the sensitivity, the specificity, the F_measure, Cohen’s Kappa, the area under the receiver operating characteristic curve (AUC), convergence speed and the statistical analysis of the Wilcoxon signed-rank test. Moreover, after training, the EDNM can simplify its neural structure by removing redundant synapses and superfluous dendrites by the neuronal pruning mechanism. Finally, the simplified structural morphology of the EDNM can be replaced by a logic circuit (LC) without sacrificing accuracy. It is worth emphasizing that once implemented by an LC, the model has a significant advantage over other classifiers in terms of speed when handling big data. Consequently, our proposed model can serve as an efficient medical classifier with excellent performance.  

[**[JC011](https://chengtang-ai.github.io/JournalPublications/)**], [**[JC008](https://chengtang-ai.github.io/JournalPublications/)**], [**[JC006](https://chengtang-ai.github.io/JournalPublications/)**]  

<h2 id="rau">
Time Series Forecasting
</h2>

[**[JF002](https://chengtang-ai.github.io/JournalPublications/)**]. **Artificial immune system training algorithm for a dendritic neuron model.**
![image](https://github.com/user-attachments/assets/58a28319-d3a1-41fc-92ec-2d679e652db1)
Dendritic neuron model (DNM), which is a single neuron model with a plastic structure, has been applied to resolve various complicated problems. However, its main learning algorithm, namely the back-propagation (BP) algorithm, suffers from several shortages, such as slow convergence rate, being easy to fall into local minimum and over-fitting problems. That largely limits the performances of the DNM. To address this issue, another bio-inspired learning paradigm, namely the artificial immune system (AIS) is employed to train the weights and thresholds of the DNM, which is termed AISDNM. These two methods have advantages on different issues. Due to the powerful global search capability of the AIS, it is considered to be efficient in improving the performance of the DNM. To evaluate the performance of AISDNM, eight classification datasets and eight prediction problems are adopted in our experiments. The experimental results and statistical analysis confirm that the AISDNM can exhibit superior performance in terms of accuracy and convergence speed when compared with the multilayer perceptron (MLP), decision tree (DT), the support vector machine with the linear kernel (SVM-l), the support vector machine with the radial basis function kernel (SVM-r), the support vector machine with the polynomial kernel (SVM-p) and the conventional DNM. It can be concluded that the reasonable combination of two different bio-inspired learning paradigms is efficient. Furthermore, for the classification problems, empirical evidence also validates the AISDNM can delete superfluous synapses and dendrites to simplify its neural structure, then transform the simplified structure into a logic circuit classifier (LCC) which is suitable for hardware implementation. The process does not sacrifice accuracy but significantly improves the classification speed. Based on these results, both the AISDNM and the LCC can be regarded as effective machine learning techniques to solve practical problems.  

[**[JF006](https://chengtang-ai.github.io/JournalPublications/)**]  
[**[JS007](https://chengtang-ai.github.io/JournalPublications/)**], [**[JS004](https://chengtang-ai.github.io/JournalPublications/)**], [**[JS003](https://chengtang-ai.github.io/JournalPublications/)**]  
[**[JC014](https://chengtang-ai.github.io/JournalPublications/)**], [**[JC009](https://chengtang-ai.github.io/JournalPublications/)**], [**[JC007](https://chengtang-ai.github.io/JournalPublications/)**], [**[JC006](https://chengtang-ai.github.io/JournalPublications/)**], [**[JC004](https://chengtang-ai.github.io/JournalPublications/)**]  
[**[CC004](https://chengtang-ai.github.io/ConferencePublications/)**]  

<h2 id="cau">
Computer Vision
</h2>

[**[JF004](https://chengtang-ai.github.io/JournalPublications/)**]. **A novel motion direction detection mechanism based on dendritic computation of direction-selective ganglion cells.**  
![image](https://github.com/user-attachments/assets/6f41a1b7-3c72-4617-a65c-5e60976597c5)
The visual system plays a vital role when the brain receives and processes information. Approximately ninety percent of the information received by the brain comes from the visual system, and motion detection is a crucial part of processing visual information. To further understand the generation of direction selectivity, we propose a novel apparent motion detection mechanism using direction-selective ganglion cells (DSGCs). Considering the simplicity of neural computation, each neuron is responsible for detection in a specific direction. For example, eight neurons are employed to detect movements in eight directions, and local information is collected by scanning. The global motion direction is obtained according to the degree of activation of the neurons. We report that this method not only has striking biological similarities with hypercomplex retinal cells, but can also make accurate discriminations. The pioneering mechanism may lead to a new technique for understanding more complex principles of the visual nervous system.  

[**[JS002](https://chengtang-ai.github.io/JournalPublications/)**]. **The mechanism of orientation detection based on color-orientation jointly selective cells.**   
![image](https://github.com/user-attachments/assets/4e1f4429-167d-4874-8166-737f6b598a4b)  
This paper discusses the visual mechanism of global orientation detection and the realization of a mechanism-based artificial visual system for two-dimensional orientation detection tasks. For interpretation and practicability, we introduce the visual mechanism into the design of a detection system. We first propose an orientation detection mechanism according to the color-orientation jointly selectivity cortical neuron character. We assume that part of the orientation detection tasks is completed by the color-orientation jointly selective cells that are only responsible for orientation detection locally. Each cell can only be activated by stimuli with a specific orientation angle and the preferred color. We realize these cells by the McCulloch–Pitts neuron model and extend them to a two-dimensional version. In each local receptive field, there are four separate color-orientation jointly selective cells responsible for orientation detection, and their optimal responsive color corresponds to the central location’s color. Every local region connects such a set of cells. Subsequently, by these sets of these cells, we can collect all local information and obtain the global orientation according to the local activations. The type of local orientation angle recognized the most corresponds to the global orientation. Finally, a mechanism-based artificial visual system (AVS) is implemented. Several simulations and comparative experiments are provided to verify the effectiveness and generalization of the proposed orientation detection scheme and the superiority of the AVS to popular classification networks in orientation detection tasks. In addition, the feature extraction ability of AVS is shown to accelerate the learning and noise immunity of neural networks.  

[**[JS005](https://chengtang-ai.github.io/JournalPublications/)**]  
[**[JC016](https://chengtang-ai.github.io/JournalPublications/)**], [**[JC014](https://chengtang-ai.github.io/JournalPublications/)**], [**[JC012](https://chengtang-ai.github.io/JournalPublications/)**], [**[JC010](https://chengtang-ai.github.io/JournalPublications/)**], [**[JC008](https://chengtang-ai.github.io/JournalPublications/)**]   
[**[CC019](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC015](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC013](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC010](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC008](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC007](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC006](https://chengtang-ai.github.io/ConferencePublications/)**]  

<h2 id="cau">
Natural Language Processing
</h2>

[**[JC017](https://chengtang-ai.github.io/JournalPublications/)**]  
[**[CC021](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC020](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC017](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC016](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC014](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC011](https://chengtang-ai.github.io/ConferencePublications/)**]  

<h2 id="fau">
Learning Analytics
</h2>

[**[JC013](https://chengtang-ai.github.io/JournalPublications/)**]  
[**[CF013](https://chengtang-ai.github.io/ConferencePublications/)**]  
[**[CC021](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC020](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC017](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC016](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC012](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC011](https://chengtang-ai.github.io/ConferencePublications/)**]  

<h2 id="rau">
AI for Drug Design
</h2>

[**[JC015](https://chengtang-ai.github.io/JournalPublications/)**]  

<h2 id="cau">
Explainable AI (XAI)
</h2>

[**[JF002](https://chengtang-ai.github.io/JournalPublications/)**]  
[**[JS007](https://chengtang-ai.github.io/JournalPublications/)**], [**[JS006](https://chengtang-ai.github.io/JournalPublications/)**], [**[JS003](https://chengtang-ai.github.io/JournalPublications/)**], [**[JS002](https://chengtang-ai.github.io/JournalPublications/)**]   
[**[JC003](https://chengtang-ai.github.io/JournalPublications/)**], [**[JC002](https://chengtang-ai.github.io/JournalPublications/)**]   
[**[CF003](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CF001](https://chengtang-ai.github.io/ConferencePublications/)**]  
[**[CC018](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC009](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC004](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC003](https://chengtang-ai.github.io/ConferencePublications/)**]  

<h2 id="fau">
Optimization
</h2>

[**[JF005](https://chengtang-ai.github.io/JournalPublications/)**], [**[JF003](https://chengtang-ai.github.io/JournalPublications/)**], [**[JF002](https://chengtang-ai.github.io/JournalPublications/)**]   
[**[JS001](https://chengtang-ai.github.io/JournalPublications/)**]  
[**[JC009](https://chengtang-ai.github.io/JournalPublications/)**], [**[JC005](https://chengtang-ai.github.io/JournalPublications/)**], [**[JC003](https://chengtang-ai.github.io/JournalPublications/)**], [**[JC001](https://chengtang-ai.github.io/JournalPublications/)**]   
[**[CF002](https://chengtang-ai.github.io/ConferencePublications/)**]  
[**[CC018](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC005](https://chengtang-ai.github.io/ConferencePublications/)**], [**[CC001](https://chengtang-ai.github.io/ConferencePublications/)**]  


<script async src="https://npm.elemecdn.com/penndu@1.0.0/bsz.js"></script>
<span id="busuanzi_container_site_pv">Total Visits: <span id="busuanzi_value_site_pv"></span>.</span>
